{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pypi.org/project/kafka-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Topics:  \n",
    "\n",
    "Every message that is feed into the system must be part of some topic. The topic is nothing but a stream of records. The messages are stored in key-value format. Each message is assigned a sequence, called Offset. The output of one message could be an input of the other for further processing.  \n",
    "\n",
    "* Producers:  \n",
    "\n",
    "Producers are the apps responsible to publish data into Kafka system. They publish data on the topic of their choice.\n",
    "\n",
    "* Consumers:  \n",
    "\n",
    "The messages published into topics are then utilized by Consumers apps. A consumer gets subscribed to the topic of its choice and consumes data.  \n",
    "\n",
    "* Broker:  \n",
    "\n",
    "Every instance of Kafka that is responsible for message exchange is called a Broker. Kafka can be used as a stand-alone machine or a part of a cluster.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZK windows install  \n",
    "1. JRE installation  \n",
    "2. ZK download http://zookeeper.apache.org/releases.html#download\n",
    "3. Copy and Rename “zoo_sample.cfg” to “zoo.cfg” in C:\\Tools\\zookeeper-3.4.9\\conf\n",
    "4. Create data directory in zookeeper folder.\n",
    "5. Find & edit dataDir=/tmp/zookeeper to C:\\\\Tools\\\\zookeeper\\\\zookeeper-3.4.9\\\\data using any text editor like notepad or notepad++. (change the zookeeper version as yours)\n",
    "6. dataDir=C:\\\\Tools\\\\zookeeper\\\\zookeeper-3.4.9\\\\data\n",
    "7. Add entries in System Environment Variables.\n",
    "8. Add in System Variables ZOOKEEPER_HOME = C:\\Tools\\zookeeper-3.4.9\n",
    "9. Edit System Variable named “Path” and append this in the last ;%ZOOKEEPER_HOME%\\bin;\n",
    "10. Open command prompt and type zkserver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kafka windows install\n",
    "1. Go to config folder in Apache Kafka and edit “server.properties” using any text editor.\n",
    "2. Find log.dirs and repelace after “=/tmp/kafka-logs” to “=C:\\\\Tools\\\\kafka_2.10–0.10.1.1\\\\kafka-logs” (change your version number)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kafka windows setup  \n",
    "Open command prompt and go to your Apache Kafka directory and run following command.  \n",
    "`.\\bin\\windows\\kafka-server-start.bat .\\config\\server.properties`  \n",
    "\n",
    "Topic creation:  \n",
    "`kafka-topics.bat — create — zookeeper localhost:2181 — replication-factor 1 — partitions 1 — topic some_kafka_topic`  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Producer creation:  \n",
    "    \n",
    "`kafka-console-producer.bat — broker-list localhost:9092 — topic some_kafka_topic`  \n",
    "The broker-list parameter specifies the brokers to be connected as <node_address:port> — that is, localhost:9092."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consumer creation:  \n",
    "`kafka-console-consumer.bat -bootstrap-server localhost:2181 -topic sql-insert`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running all four components (zookeeper, broker, producer, and consumer) in different terminals, you will be able to enter messages from the producer’s terminal and see them appearing in the subscribed consumer’s terminal. If everything works fine, you will be able to push and see messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linux/macOS ZK + Kafka\n",
    "Jāielādē Kafka no Apache foundation lapas.  \n",
    "Kafka līdzi nāk zookeeper servera palaišanas skripts  \n",
    "`bin/zookeeper-server-start.sh config/zookeeper.properties`  \n",
    "\n",
    "Un brokera (servera / nodes) palaišanas skripts  \n",
    "`bin/kafka-server-start.sh config/server.properties`  \n",
    "\n",
    "Tad uz brokera ir jāizveido topiks  \n",
    "`bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic some_kafka_topic`  \n",
    "\n",
    "Palaižot to pašu skriptu ar citiem flagiem var redzēt pilno sarakstu ar topikiem  \n",
    "`bin/kafka-topics.sh --list --zookeeper localhost:2181` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Jāinstalē bibliotēka vai nu ar termināli vai ar anaconda promptu:\n",
    "# pip install kafka-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import loads\n",
    "from json import dumps\n",
    "import time\n",
    "\n",
    "from kafka import KafkaConsumer\n",
    "from kafka import KafkaProducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we assume that Zookeeper is running default on localhost:2181 and Kafka on localhost:9092.\n",
    "# consumer = KafkaConsumer('some_kafka_topic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = KafkaProducer(bootstrap_servers=['localhost:9092'], value_serializer=lambda x: json.dumps(x).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer = KafkaConsumer(\n",
    "    'numtest',\n",
    "     bootstrap_servers=['localhost:9092'],\n",
    "     auto_offset_reset='earliest',\n",
    "     enable_auto_commit=True,\n",
    "     group_id='my-group',\n",
    "     value_deserializer=lambda x: json.loads(x.decode('utf-8')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The first argument is the topic, numtest in our case.\n",
    "* `bootstrap_servers=[‘localhost:9092’]`: same as our producer\n",
    "* `auto_offset_reset=’earliest’`: one of the most important arguments. It handles where the consumer restarts reading after breaking down or being turned off and can be set either to earliest or latest. When set to latest, the consumer starts reading at the end of the log. When set to earliest, the consumer starts reading at the latest committed offset. And that’s exactly what we want here.\n",
    "* `enable_auto_commit=True`: makes sure the consumer commits its read offset every interval.\n",
    "* `auto_commit_interval_ms=1000ms`: sets the interval between two commits. Since messages are coming in every five second, committing every second seems fair.\n",
    "* `group_id=’counters’`: this is the consumer group to which the consumer belongs. Remember from the introduction that a consumer needs to be part of a consumer group to make the auto commit work.\n",
    "* The value deserializer deserializes the data into a common json format, the inverse of what our value serializer was doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tagad atveriet jaunu termināli, ielogojieties ar ssh tajā pašā VM, \n",
    "# atveriet pitona shellu,\n",
    "# izdariet visus nepieciešamos importus,\n",
    "# Un izpildiet divas sekojošās rindiņas\n",
    "data = {'number' : 2}\n",
    "producer.send('numtest', value=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for message in consumer:\n",
    "    message = message.value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

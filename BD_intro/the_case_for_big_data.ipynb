{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ievads lielajos datos  \n",
    "Atbildēsim uz sekojošajiem jautājumiem:  \n",
    "* Kā dators veic aprēķinus? Ko tas nozīmē priekš darba ar datiem?  \n",
    "* Kas ir lielie dati?  \n",
    "* Kādas ir tradicionālo (relāciju) datubāžu iespēju robežas? Kāpēc tādas eksistē?  \n",
    "* Kas ir skaitļošanas kapacitātes mērogošana un kā to var darīt?\n",
    "* Kas ir skaitļošanas paralelizācija?\n",
    "* Kas ir CAP teorēma?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kā dators veic aprēķinus?  \n",
    "Divas galvenās komponentes: Procesors un (operatīvā)atmiņa  \n",
    "Procesors izpilda instrukcijas, kas kopā ar kopā ar informāciju, ar kuru šīs darbības jāveic, tiek glabātas operatīvajā atmiņā. Procesors arī veic rakstīšanas/lasīšanas darbības no operatīvās atmiņas.  \n",
    "Atmiņa faktiski sastāv no ārkārtīgi liela skaita atmiņas 'šūnu', kurā tiek glabātas bināras vērtības elektriskā sprieguma veidā. \n",
    "\n",
    "Dati tiek reprezentēti atmiņā kā binārā koda virkne fiksētā garumā.  \n",
    "0 - 0  \n",
    "1 - 1  \n",
    "2 - 10  \n",
    "3 - 11  \n",
    "4 - 100  \n",
    "5 - 101  \n",
    "6 - 110  \n",
    "7 - 111  \n",
    "8 - 1000  \n",
    "9 - 1001  \n",
    "10 - 1010  \n",
    "11 - 1011  \n",
    "12 - 1100  \n",
    "\n",
    "Priekš 16 bitu skaitļa ir nepieciešams rezervēt 16 atmiņas šūnas. Lielākais skaitlis, ko var reprezentēt ar 16 atmiņas šūnām ir...?  \n",
    "\n",
    "Par atmiņu var domāt kā lenti uz kuras ir atlikti secīgi vieninieki un nulles un par procesoru var domāt kā par 'vilcieniņu', kas var pārvietoties turp un atpakaļ pa šo lenti, atkarībā no instrukcijām, lasot , salīdzinot un rakstot lentē vieniniekus vai nulles, vienlaikus arī dažas no šīm vērtībām pieglabājot tās sev piemītošajos cache'os.    \n",
    "Instrukcijas, pat lai vienkārši reizinātu divus skaitļus, ir diezgan sarežģītas un par laimi par tām ir padomāts.  \n",
    "**Atkarībā no uzdevuma, kādu instrukciju izpildei var būt nepieciešama ļoti gara lente (atmiņas ziņā smags aprēķins) vai arī daudz pārvietošanās/lasīšanas/rakstīšanas/salīdzināšanas operāčiju (skaitliski smags aprēķins)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kas ierobežo datu apstrādes kapacitāti/ātrumu?\n",
    "* Hardware <!-- cik gara lente, cik ātrs/viltīgi uzbūvēts 'vilcieniņš' -->\n",
    "* **Lietotie algoritmi un datu struktūras**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vienkārši algoritmisko ierobežojumu piemēri:   \n",
    "Sakārtošana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time as tm\n",
    "\n",
    "# # 7 elementi:\n",
    "arr = [8,9195,14,9090,21, 1,357]\n",
    "\n",
    "# # 14 elementi:\n",
    "# arr = [1,6,12,76,34,919,4675,764,0,3,3,357]\n",
    "\n",
    "\n",
    "# # 28 elementi:\n",
    "# arr = [1,7,4,6,12,7,6,34,919,4675,764,0,3,3,357,0,6,37356,2,2352527,11,11,78,8679,13,515,24534,47,357]\n",
    "\n",
    "\n",
    "n = len(arr) \n",
    "find_me = 357"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bubble sort algoritms, vidēji n * n complexity\n",
      "saraksta garums: 7\n",
      "2.804924e-07\n",
      "[1, 8, 14, 21, 357, 9090, 9195]\n"
     ]
    }
   ],
   "source": [
    "# Sekojošo divu piemēru Python kods ir ņemts no avota:\n",
    "# https://www.geeksforgeeks.org/sorting-algorithms/\n",
    "\n",
    "print(\"bubble sort algoritms, vidēji n * n complexity\")\n",
    "print(\"saraksta garums:\",n)\n",
    "for count in range(0,50):\n",
    "    # Python program for implementation of Bubble Sort \n",
    "    # Traverse through all array elements \n",
    "    start_time = tm()\n",
    "    for i in range(n): \n",
    "        # Last i elements are already in place \n",
    "        for j in range(0, n-i-1): \n",
    "            # traverse the array from 0 to n-i-1 \n",
    "            # Swap if the element found is greater \n",
    "            # than the next element \n",
    "            if arr[j] > arr[j+1] : \n",
    "                arr[j], arr[j+1] = arr[j+1], arr[j] \n",
    "    avg = (tm() - start_time)/51 # Takes the average of the runtimes logged\n",
    "print('{:e}'.format(avg))\n",
    "print(arr)\n",
    "# Source:\n",
    "# https://www.geeksforgeeks.org/sorting-algorithms/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"insertion sort algoritms vidēji 2 * n complexity\")\n",
    "print(\"saraksta garums:\",n)\n",
    "# temp_arr = arr\n",
    "# arr.sort()\n",
    "for count in range(0,50):\n",
    "    start_time = tm()\n",
    "    # Traverse through 1 to len(arr) \n",
    "    for i in range(1, len(arr)): \n",
    "        key = arr[i] \n",
    "        # Move elements of arr[0..i-1], that are \n",
    "        # greater than key, to one position ahead \n",
    "        # of their current position \n",
    "        j = i-1\n",
    "        while j >= 0 and key < arr[j] : \n",
    "                arr[j + 1] = arr[j] \n",
    "                j -= 1\n",
    "        arr[j + 1] = key\n",
    "    avg = (tm() - start_time)/51\n",
    "print('{:e}'.format(avg))\n",
    "print(arr)\n",
    "# arr = temp_arr\n",
    "\n",
    "# Source:\n",
    "# https://www.geeksforgeeks.org/sorting-algorithms/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vienkārši algoritmisko ierobežojumu piemēri:  \n",
    "Atrašana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Linear search meklesanas algoritms, videji n/2 sarezgitiba, sliktakaja gad n sarezgitiba\")\n",
    "print(\"saraksta garums:\",n)\n",
    "temp_arr = arr\n",
    "# arr = temp_arr.sort()\n",
    "for count in range(0,50):\n",
    "    start_time = tm()\n",
    "    index = 0\n",
    "    found = False\n",
    "    for element in arr:\n",
    "        if element == find_me:\n",
    "            found = True\n",
    "            found_index = index\n",
    "        else:\n",
    "            index+=1\n",
    "    if not found:\n",
    "        print(\"elementa saraksta nav\")\n",
    "    \n",
    "    avg = (tm() - start_time)/51\n",
    "print('{:e}'.format(avg))\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"binary search piemērs\")\n",
    "print(\"saraksta garums:\",n)\n",
    "temp_arr = arr\n",
    "temp_arr.sort()\n",
    "for count in range(0,50):\n",
    "    start_time = tm()\n",
    "    found = False\n",
    "    left = 0\n",
    "    right = len(arr)\n",
    "    middle = int(len(arr)/2)\n",
    "    actions = 0\n",
    "    while not found:\n",
    "        if temp_arr[middle] == find_me:\n",
    "            break\n",
    "        else:\n",
    "            if temp_arr[middle] > find_me:\n",
    "                actions+=1\n",
    "                right = middle\n",
    "                middle = int((left + right)/2)\n",
    "            else:\n",
    "                actions+=1\n",
    "                left = middle\n",
    "                middle = int((left + right)/2)\n",
    "    avg = (tm() - start_time)/51\n",
    "print('{:e}'.format(avg), \"with \", actions,\" actions\")\n",
    "print(temp_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vienkārši algoritmisko ierobežojumu piemēri: Datu struktūras.  \n",
    "* Linked list<!-- brauzera uz priekšu/atpakaļ  , direktoriju struktūra-->  \n",
    "* Hash table  <!-- datubāzu lookup, jāpastāsta dziļāk -->\n",
    "* AVL Tree <!-- Strādā ātri priekš jaunu ierakstu ievadīšanas un ierakstu dzēšanas, lēnām priekš search -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://adrianmejia.com/images/big-o-running-time-complexity.png)\n",
    "Source: https://adrianmejia.com/most-popular-algorithms-time-complexity-every-programmer-should-know-free-online-tutorial-course/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kas ir lielie dati?\n",
    "* Variety  \n",
    "* Velocity  \n",
    "* Volume  \n",
    "\n",
    "Lielie dati ir jebkuri dati, kurus kāda eksistējošā apstrādes sistēma nespēj apstrādāt vai nu pietiekoši efektīvi vai vispār.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kādas ir tradicionālo datubāzu iespēju robežas?  \n",
    "Tipiski datubāzes visu informāciju glabā atmiņā un izmanto hash table vai citas datu stuktūras, kas atļauj ātri atrast un apvienot ierakstus.  \n",
    "Ja dati ir ar lielu **dažādību** vai neparedzamu shēmu (JSON faili no web lapas ar patvaļīgu skaitu unikālu un iepriekš neparedzamu lauku), tos glabāt relāciju datubāzē varētu būt neparocīgi.  \n",
    "Ja dati ienāk lielā **ātrumā** un mēdz pārrakstīt esošos ierakstus vai arī datubāzei jābūt ļoti ātri reaģējošai (reāla laika monitorēšanas - atbildēšanas sistēmas kā rekomendācijas bāzējoties uz saturu, kas šobrīd tiek skatīts, fraud detection), tad pie pietiekoši lieliem tabulu izmēriem, lookupi kļūs lēnāki.  \n",
    "Ja dati, ko mēs vēlamies glabāt, nemaz neietilpst datubāzes servera atmiņā, mums ir problēmas ar **ietilpību**  \n",
    "\n",
    "Galvenās problēmas, kas rodās, ir ierakstīšana no diska operatīvajā atmiņā vai no tīkla operatīvajā atmiņā notiek parāk lēni un veidojas tā saucamais pudeles kakls.  \n",
    "Vēl var būt , ka datu ir pārāk daudz, lai tīkls panestu satiksmi, bet tas nenotiek bieži un to bieži var salabot ar labāku tīkla arhitektūru vai vertikālu mērogošanu.  \n",
    "\n",
    "Vēl viens algoritmisks trūkums datubāzēm ir, ka, atkarībā no izmantotās datu struktūras, datu bāzē varētu būt ātri atgriezt rezultātus, bet lēni ierakstīt kaut ko jaunu.  \n",
    "\n",
    "Relāciju datubāzes tipiski labi nepanes datu apjomus, kas ir lielāki par pāris desmitiem gigabaitu, pat ja pietiek atmiņas, lai ietilpinātu datus un ar tiem darbotos. BET pat ja jūsu datubāze ir lielāka par 30gb, jums droši vien tāpat nevajag lielo datu risinājumus, bet labāku datu shēmu / arhitektūru."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kas ir skaitļošanas kapacitātes mērogošana un kā to var darīt?  \n",
    "Pieņemsim, ka mums ir ļoti liela un ļoti aktīva datubāze, kura kļūst aizvien lielāka un drīz sasniegs savu kapacitāti. Šī ir problēma un mums ir jāizlemj vai mēs vēlamies uzlabot serveri uz kura šī datubāze atrodas vai arī nopirkt vēl vienu tādu pašu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stratēģija, kurā mēs būvējam lielāku serveri tiek dēvēta par **scale-up** jeb vertical scaling.  \n",
    "Stratēģija, kurā mēs nopērkam vēl vienu serveri tiek dēvēta par **scale-out** jeb horizontal scaling.  \n",
    "\n",
    "\n",
    "Ja mēs skaidri zinam, ka datubāze neturpinās augt, labāka ideja varētu būt vertikāla mērogošana, bet pie zināmiem datu apjomiem un prasībām, tas kļūst dārgi, nedroši un varbūt pat neiespējami, tāpēc lielo datu pasaulē problēmas tiek risinātas ar horizontālo pieeju.  \n",
    "Skaitļošanas jauda tiek sadalīta uz vairākām, lētākām mašīnām, tā vietā, lai būvētu vienu lielu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kas ir skaitļošanas paralelizācija?\n",
    "Ideālā gadījumā, mēs varētu paņemt kādu skaitļošanas problēmu un sadalīt to vairākās daļās, kuras tiek risinātas vienlaicīgi un neatkarīgi. \n",
    "https://computing.llnl.gov/tutorials/parallel_comp/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ja mēs veicam kāda procesa paralelizāciju uz vairāk kā viena servera, tas nāk gan ar papildus iespējām, gan izaicinājumiem.  \n",
    "\n",
    "Iespējas:\n",
    "* Paralēla datu glabāšana uz trim serveriem atļautu, piemēram, search algoritmam sadalīt visu sarakstu, kurā ir jāatrod dotā vērtība trīs daļās, katram serverim viena, kas skaitļošanas laiku samazinātu uz n/3.  \n",
    "* Lai dati nebūtu jāsūta uz katru no šiem serveriem, tie var atrasties turpat uz vietas, glabājot datus paralēli.  \n",
    "* Paralēla datu glabāšana un apstrāde mums atļauj nodrošināties pret to, ka , ja kāds individuāls serveris cieš bojājumus, tīkla pārrāvumu vai programmistisku kļūdu, mums tāpat ir pieejami skaitļošanas resursi un dati uz kuriem  šo skaitļošanu veikt.\n",
    "\n",
    "Izaicinājumi:\n",
    "* Transakcijas nav tik vienkāršas\n",
    "* Aprēķinu tāpat nevar veikt ātrāk kā garāko neatkarīgo aprēķinu virkni. Paralelizācija nav subraba lode visām problēmām jo dažreiz problēmu paralelizēt nevar vai ir sarežģīti. \n",
    "<!-- group by sarežģīti -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kas ir CAP teorēma?  \n",
    "C - Consistency. Visas datu kopijas ir vienādas visur  \n",
    "A - Availability. Neviens write neatgriež kļūdu.  \n",
    "P - Partition tolerance. Distributētā sistēma turpina operēt, ja kāda partīcija/serveris pazaudē savienojumu ar pārējām partīcijām."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

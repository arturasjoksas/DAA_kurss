{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vienkāršākā taisnes piedzīšana. Cost / Loss funkcija  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dotā problēma  \n",
    "Pieņemsim, ka mums ir punktu mākonis, kurš šķietami labi atbilst lineārai sakarībai.   \n",
    "Pieņemsim, ka mums ir sekojošs grafiks (tikai grafiks), kurā mums ir atlikti dati par degviela patēriņiem relatīvi pret nobrauktiem kilometriem kādai vienāda modeļa un gada automašīnu grupai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X,Y = make_regression(random_state=0,n_features=1, noise=10) # Ģenerē divus numpy masīvus ar troksni Y masīvā, lai simulētu reālus datus.\n",
    "\n",
    "# Dati ir jātransformē. \n",
    "# Negatīviem nobraukumiem un patēriņiem nav nekādas jēgas.\n",
    "\n",
    "# Šis ir vienkāršs datu mērogošanas piemērs.\n",
    "X = X[:,0]\n",
    "X = X + abs(X.min())\n",
    "Y = Y + abs(Y.min())\n",
    "\n",
    "# Paterins = koeficients * nobraukums + konstante\n",
    "# Teiksim VW Passat 2005 uz 100 km patērē 4 - 6,3 l. \n",
    "# Funkcijas outputam jābūt ar mērvienību litri.\n",
    "# Funkcijas inputs ir kilometri.\n",
    "# Slīpuma koeficientam tad ir jābūt ar mērvienību, litri/kilometri\n",
    "# VW Passat patēŗiņa slīpuma koeficients tad būs aptuveni 5l uz 100 km jeb vnk 0.05 l/km\n",
    "\n",
    "# Koriģē Y vērtības, pēc defaulta make_regression() slīpuma koeficients ir 40. Lai tās atbilstu reālistiskam nobraukumam,\n",
    "# Būtu jādala ar 40 un jāreizina ar 0.05 t.i. jādala ar vēl 20. Rezultātā dala ar 800.\n",
    "Y = Y/800\n",
    "\n",
    "\n",
    "df = pd.DataFrame.from_dict({'X':X,'Y':Y})\n",
    "print(X.shape,Y.shape)\n",
    "plt.xlabel('Nobraukums km')\n",
    "plt.ylabel('Paterins litri')\n",
    "plt.scatter(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Ar sklearn lineārā modeļa bibliotēku apskatīsim kādu slīpuma koeficientu varam sagaidīt no šiem datiem, rēķinot manuāli\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# reg = LinearRegression(fit_intercept=False)\n",
    "# # Reshape nepieciešams, lai kolonnu vektoru pārvērstu par rindiņu vektoru\n",
    "# reg.fit(df['X'].values.reshape(-1,1),df['Y'].values.reshape(-1,1))\n",
    "# reg.coef_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sympy\n",
    "from sympy import symbols, exp, Eq, Sum, Function\n",
    "from sympy import symbol\n",
    "from sympy.abc import a,b,i,j,l,m,n,k, x\n",
    "\n",
    "y, Y, x, X, P, n, N, E, var, Cost, sigma, Sigma, lmbd = symbols('y Y x X P n N E var Cost σ Σ λ')\n",
    "\n",
    "f = Function('f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Cik litrus iztērēs VW passat automašīna, kas nobrauks 140 km? Kā mēs to varētu aprēķināt tikai no šiem datiem?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mēs uz šo jautājumu varētu atbildēt, ja iegūtu kādu vienkāršu skaitlisku sakarību, kura kā ievadu ņem nobrauktos kilometrus un kā izvadu atgriež iztērēto degvielas apjomu litros. Šai sakarībai arī labi būtu jāapraksta mūsu datus un tādējādi, ja mums nav iemesla domāt, ka degvielas patērēšanas mehānisms būtiski mainās pie lielākiem nobraukumiem, mēs varētu šo sakarību arī ekstrapolēt nobraukumiem, kas pirms tam nav redzēti.  \n",
    "\n",
    "\n",
    "Ir redzams, ka šos datus labi var aprakstīt kāda taisne ar pozitīvu slīpuma koeficientu.\n",
    "Vispārīgs taisnes vienādojums (ar 1 neatkarīgo un 1 atkarīgo mainīgo, tātad 2 dimensijās) ir sekojošs: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Eq(y,a*x+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**y** būs izvadītā vērtība un **x** ir ievadītā vērtība.  \n",
    "Būtu vienīgi jāatrod koeficienti a un b, kas veido taisni, kas atbilst datiem un ar šo 'problēmu' ir saistīti sekojošie jautājumi:  \n",
    "* **Kā atrast šo koeficientu vērtības?** Minēt? Izveidot algoritmu? Kā šim algoritmam būtu jāizskatās? Varbūt var analītiski?\n",
    "* **Kā pateikt, ka esam atraduši labu taisni? Kā salīdzināt divaus koeficientu komplektus?** Būtu jāizdomā metrika, kas apraksta to, cik labi taisne atbilst punktiem.\n",
    "* **Kā pateikt, ka esam atraduši labāko iespējamo taisni?**  \n",
    "\n",
    "Sāksim vispirms ar otro jautājumu.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kā pateikt, ka esam atraduši labu taisni? Kā novērtēt taisnes 'labumu'?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import mglearn\n",
    "mglearn.plots.plot_linear_regression_wave()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Šādā piemērā ir uzvilkta kāda taisne ar slīpuma koeficientu **w\\[0\\]** un brīvo locekli **b**, kas aptuveni apraksta punktu mākoņa lineāro sakarību.  \n",
    "Šādā vienkāršā piemērā mēs vizuāli ļoti labi varam novērtēt vai taisne apraksta šos punktus labi vai slikti un 2 dimensijās mēs taisnes koeficientus pat varētu uzminēt, bet ko darīt situācijā, kad mums ir 5 vai vairāk neatkarīgiem mainīgie? 5+1 dimensijās ar aci pateikt nevarētu. To var izdarīt ieviešot funkciju, kura atgriež skaitli, kurš raksturo cik labi vai slikti taisne atbilst punktiem.  \n",
    "\n",
    "Šādu funkciju sauc par **Cost** jeb **Loss** funkciju. (latviski Zaudējumu funkcija(?))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kritērijs labai taisnei - Cost funkcija. Koncepts un uzvedība.  \n",
    "Cost funkcijas ir izmantotas visa veida machine learning un klasiskās statistikas problēmās. Regresijas problēmās (Lineārās un nelineārās piedzīšanas, neironu tīkli) tipiski izmanto savādākas Cost funkcijas kā klasifikācijas/klasterizācijas problēmās (K-means, K-nn, DecisionTree u.t.t.)\n",
    "Priekš regresijas/neironu tīklu uzdevumiem tipiski tiek izmantotas šādas:  \n",
    "* Klasiskā kvadrātiskā Cost funkcija, arī pazīstama mazāko kvadrātu metode, \n",
    "* Vidējā absolūtā kļūda,\n",
    "* [Cross-Entropy Loss funkcija](https://en.wikipedia.org/wiki/Cross_entropy)  \n",
    "* Eksponenciālā kļūda,\n",
    "* [U.C.](https://stats.stackexchange.com/a/154880)\n",
    "\n",
    "Cost funkcija vienmēr izmanto modeli, kuram jāpiedzen parametri.  \n",
    "Cost funkcija atgriež skaitli, kurš raksturo modeļa outputa nobīdi no datiem.  \n",
    "Cost funkcijai vienmēr jāatbilst sekojošiem kritērijiem:  \n",
    "* Funkcija atgriež vienu vienīgu skaitli, neatkarīgi no koeficientu un datu punktu skaita (Funkcija ir skalāra),\n",
    "* Funkcija ir uzrakstāma kā vidējā vērtība\n",
    "* Funkcijai jābūt gludai (Precīzāk, ar definējamu, galīgu slīpuma koeficientu visur)\n",
    "* Funkcijas vērtība ir lielāka, ja modelis datiem atbilst sliktāk,\n",
    "* Funkcijas vērtība ir mazāka, ja modelis datiem atbilst labāk  \n",
    "\n",
    "\n",
    "!!  \n",
    "Uz reāliem datiem cost funkcijas vērtība nemēdz sasniegt nulli, ja vien tie perfekti neapraksta datus (ārkārtīgi mazvarbūtīgi, pat aizdomīgi, droši vien falsificēti dati) vai arī modelim ir vairāk parametru, kā mums ir datu punktu (Caur jebkuriem diviem punktiem ir iespējams novilkt perfektu taisni, caur jebkuriem trim kvadrātisku fciju u.t.t.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Vienkāršākais Cost funkcijas piemērs - kvadrātiskā kļūda  \n",
    "Apskatīsim vienkāršu cost funkcijas piemēru - kvadrātisko kļūdu. Sauktu arī par mazāko kvadrātu metodi.   \n",
    "No sākuma mums vajag tabulu ar datiem, kuru tad izmantosim, lai piedzītu taisni. Izmantosim degvielas patēriņa datus, kurus jau uzģenerējām."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vispārināsim modeļa konceptu.  \n",
    "Mēs vēlamies atgriezt skaitli, atkarībā no inputa **x** un koeficientiem **a** un **b**. Mūsu funkcijai var būt patvaļīgs koeficientu skaits un patvaļīgs neatkarīgo mainīgo skaits.  \n",
    "\n",
    "\n",
    "Neatkarīgos mainīgos apzīmēsim ar **x_j** un koeficientus ar **w**.  \n",
    "Datu punktu skaitu apzīmēsim ar **l** un datu punktu vektoru apzīmēsim ar $\\hat{y}$  \n",
    "\n",
    "Pēc šādas notācijas, mums ir **j** neatkarīgie mainīgie un **k** koeficienti:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_i, y_i,x_j,w_k = symbols('x_i y_i x_j w_k')\n",
    "f(x_j,w_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mūsu lineārais modelis y = b + ax, tad būtu pierakstāms šādi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Eq(symbols('y'),symbols('w_1')*symbols('x') + symbols('w_0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Galvenā kvadrātiskās kļūdas ideja ir aprēķināt datu punktu $\\hat{y}$ un modeļa paredzējuma starpību kvadrātus. Jo labāka būs taisne, jo mazāka būs summa.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eq(symbols('diff_i'),symbols('\\hat{y_i}') - symbols('y_i'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Eq(symbols('diff_i'),symbols('\\hat{y_i}') - (symbols('w_1')*symbols('x_i') + symbols('w_0')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Eq(Cost,Sum(symbols('diff_i^2'),(i,1,symbols('l'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ja mēs patvaļīgi izvēlamies parametrus, tad iegūsim kādu cost funkcijas novērtējumu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uzdevums: \n",
    "# y = ax + b\n",
    "# Sekojot instrukcijām, papildiniet funkciju cost, kas kā argumentus ņem \n",
    "# DataFrame objektu df un divus koeficientus. \n",
    "# Funkcijai jāatgriež vērtība, kas tiek aprēķināta ar kvadrātisko kļūdu.\n",
    "\n",
    "def cost(dati,a,b):\n",
    "    # 1.Vispirms, izmantojot modeļa parametrus a un b, izveidojiet un aizpildiet kolonnu 'modelis ar modeļa vērtībām'\n",
    "    # 2. Šeit jau ir implementēta kvadrātiskā starpība un tās ielikšana kolonnā 'diff^2'.\n",
    "    dati['diff^2'] = (dati['Y'] - dati['modelis'])**2\n",
    "    # 3. Sasummējiet un atgrieziet diff^2 kolonnas vērtības\n",
    "    return dati['diff^2'].sum()\n",
    "    \n",
    "    \n",
    "cost(df,0.05,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uzdevums:\n",
    "# Paspēlējieties ar dažādām a un b vērtībām, mēģiniet atrast labāko kombināciju.\n",
    "cost(df,0.0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atbildēsim tagad uz pirmo jautājumu.\n",
    "## Kā atrast koeficientu vērtības?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minēšana\n",
    "Paspēlējoties ar koeficientu a un b vērtībām, mēs efektīvi minējām vērtības un redzējām, ka cost funkcija mums atgrieza vērtības pie dažādiem koeficientu pāriem.  \n",
    "Cik efektīva vispār varētu būt minēšana?  \n",
    "Tipiskā programmētāja pieeja šādā gadījumā būtu automatizēt minēšanu un iziet cauri lielam skaitam parametru kombināciju, pārbaudot katru kombināciju un atceroties pie kādiem parametriem ir bijusi zemākā cost funkcijas vērtība. Šāda metode patiesībā ir diezgan efektīva.  \n",
    "\n",
    "Metodi, kad mēs ejam cauri dažādām inputu kombinācijām un meklējam kādu kombināciju vai kombinācijas, kas atgriež vēlamo outputu vai outputus sauc par **grid search**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arange = np.linspace(0,1,101) # 3 argumenti: start, stop, elementu skaits. Kādus intervālus izvēlēties? Cik blīvus?\n",
    "brange = np.linspace(0,1,101)\n",
    "\n",
    "mincost = 500000\n",
    "coefs = []\n",
    "costs = []\n",
    "for a in arange:\n",
    "    for b in brange:\n",
    "        newcost = cost(df,a,b)\n",
    "        if newcost <= mincost:\n",
    "            coefs.append([a,b])\n",
    "            costs.append(newcost)\n",
    "            mincost = newcost\n",
    "\n",
    "print(coefs[-1], costs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jautājums: \n",
    "# Kāda ir sakarība starp režģa blīvumu un cost funkcijas izsaukšanas reižu skaitu? \n",
    "\n",
    "# Ar tādu pašu režģa blīvumu un intervālu galapunktiem, \n",
    "# kāda būtu šī sakarība, ja lineārajai cost funkcijai būtu 4 neatkarīgi mainīgie t.i. 4 koeficienti, kurus fitot? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minēšana ar grid search, lai gan strādā, pieder pie 'brute force' algoritmu klases un ir ar ārkārtīgi sliktu [algoritmisko laika sarežģītību](https://en.wikipedia.org/wiki/Time_complexity).  \n",
    "\n",
    "Eksistē efektīvāki risinājumi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent  \n",
    "Pie vienas fiksētas datu kopas, variējot a un b parametrus, mēs iegūstam dažādas Cost funkcijas vērtības, atkarībā no a un b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eq(symbols('Cost_x=const'),f(symbols('w'),symbols('x_const')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kas novienkāršojās uz:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eq(symbols('Cost'),f(symbols('w')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Šeit koeficienti un neatkarīgie mainīgie ir itkā mainījušies lomām. w šeit ir divas komponentes - a un b un tagad Cost ir divu argumentu funkcija. Kļūdas funkcija izskatās aptuveni šādi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyQt5 # Iespējams ir jāinstalē ar pip\n",
    "%matplotlib qt5\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D # <--- This is important for 3d plotting \n",
    "# https://stackoverflow.com/questions/56222259/valueerror-unknown-projection-3d-once-again\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "\n",
    "# Make data.\n",
    "X = np.linspace(-1,1,101)+0.05\n",
    "Y = np.linspace(-1,1,101)\n",
    "# X = np.arange(-5, 5, 0.1)\n",
    "# Y = np.arange(-5, 5, 0.1)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "R = (X**2 + Y**2) / 5\n",
    "Z = R\n",
    "# Plot the surface.\n",
    "surf = ax.plot_surface(X, Y, Z, cmap=cm.coolwarm,\n",
    "                       linewidth=0, antialiased=False)\n",
    "\n",
    "# Customize the z axis.\n",
    "ax.set_zlim(-1.01, 1.01)\n",
    "ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "ax.set_xlabel('a')\n",
    "ax.set_ylabel('b')\n",
    "ax.set_zlabel('Cost')\n",
    "# A StrMethodFormatter is used automatically\n",
    "# ax.zaxis.set_major_formatter('{x:.02f}')\n",
    "\n",
    "# Add a color bar which maps values to colors.\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mēs gribētu kaut kā no dotas funkcijas atrast parametru vērtības, kur kļūdas funkcijai ir vismazākā vērtība. \n",
    "Funkcijas minimuma atrašana ir problēma, ko var risināt gan analītiski, gan algoritmiski, bet šo problēmu risinot ir daži izaicinājumi.  \n",
    "Funkcijām var būt **globālie minimumi** un **lokālie minimumi**.  \n",
    "[<img src=\"https://upload.wikimedia.org/wikipedia/commons/6/68/Extrema_example_original.svg\">](avots)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vizuāli, atrast minimumus ir ļoti viegli, bet, ja mums būtu kādi 15 koeficienti (piem. piecpadsmit pazīmes lineārā modelī), tad ar aci pateikt vairs nav iespējams. To ir nepieciešams vispārināt. Pieiesim problēmai ar algoritmu, ko sauc par gradient descent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Gradient Descent](https://en.wikipedia.org/wiki/Gradient_descent) paļaujas uz to, ka funkcijai, kura jāminimizē, eksistē nebezgalīgi slīpuma koeficienti visā vērtību apgabalā un to, ka slīpuma koeficienti minimumos ir vienādi ar nulli.  \n",
    "Algoritma galvenā ideja ir paņemt kādu patvaļīgu parametru kombināciju, atrast visiem parametriem slīpuma koeficientus relatīvi pret funkciju un tad atjaunināt paņemtā punkta koordinātas(parametru vērtības) ar negatīvu slīpuma koeficienta vērtību reizinātu ar nelielu, pozitīvu, reālu skaitli (saukts par learning rate), efektīvi mainot parametra vērtību virzienā, kurā ir kāds lokālais minimums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_minima(costfunc,data,numiters = 60,rand=False,fixeda=0.09, fixedb=0.01):\n",
    "    if rand:\n",
    "        # Paņem random sākotnējās a un b vērtības, teiksim, ka intervālā no 0 līdz 1\n",
    "        a = random.random()\n",
    "        b = random.random()\n",
    "    else:\n",
    "        # Vai arī paņem mūsu padotas koeficientu vērtības\n",
    "        a=fixeda\n",
    "        b=fixedb\n",
    "    # Teiksim, vēlamies veikt kādu skaitu iterāciju, lai samazinātu kļūdas funkcijas vērtību\n",
    "    for k in range(0,numiters):\n",
    "        # 1. Aprēķina slīpuma koeficientu.\n",
    "        # Slīpuma koeficienta aprēķināšana ir jāveic nedaudz viltīgi. \n",
    "        # Lai aprēķinātu slīpumu kādā punktā, mēs paņemam nevis cost funkcijas vērtību pašā punktā, \n",
    "        # bet gan divas vērtības punkta apkārtnē. Pieņemsim, ka +/- 0.01 lielā apkārtnē\n",
    "        solis = 0.01\n",
    "        # Definē learning rate, būtu jābūt mazākam kā solim\n",
    "        lr = 0.001\n",
    "\n",
    "        slipums_viens_a = costfunc(data,a-solis,b)\n",
    "        slipums_divi_a = costfunc(data,a+solis,b)\n",
    "        slipums_a = (slipums_divi_a - slipums_viens_a) / (2* solis) # delta y dalīta ar delta x, lineārs tuvinājums slīpumam\n",
    "\n",
    "        slipums_viens_b = costfunc(data,a,b-solis)\n",
    "        slipums_divi_b = costfunc(data,a,b+solis)\n",
    "        slipums_b = (slipums_divi_b - slipums_viens_b) / (2* solis) # delta y dalīta ar delta x, lineārs tuvinājums slīpumam\n",
    "        \n",
    "        # 2. Update`o parametrus, izmantojot aprēķinātos slīpuma koeficientus.\n",
    "        a_new = a - slipums_a * solis * lr\n",
    "        b_new = b - slipums_b * solis * lr\n",
    "        print(costfunc(data,a_new,b_new),\" , \",a_new,b_new)\n",
    "        \n",
    "        # 3. Piešķir a un b update`otās vērtības\n",
    "        a = a_new\n",
    "        b = b_new\n",
    "    return (a_new,b_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_minima(cost,df,numiters=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jautājums: \n",
    "# Kādu iterāciju skaitu izvēlēties? Vai var izvēlēties iterāciju skaitu kā savādāk? Dinamiski?\n",
    "\n",
    "# Uzdevums:\n",
    "# Nokopējot un rediģējot funkciju find_minima(...), izveidojot find_minima_cond(...), kura izmanto nevis fiksētu iterāciju skaitu,\n",
    "# bet gan kādu apstāšanās nosacījumu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viss kods šajā notebookā ir paredzēts vairāk konceptu demonstrācijām un bibliotēkas to implementē daudz skaitliski efektīvāk. Piem. Visas šīs mūsu darbības ir veicamas divās rindiņās ar bibliotēku sklearn.  \n",
    "Nav nepieciešams riteni izgudrot no jauna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression(fit_intercept=False)\n",
    "# Reshape nepieciešams, lai kolonnu vektoru pārvērstu par rindiņu vektoru\n",
    "reg.fit(df['X'].values.reshape(-1,1),df['Y'].values.reshape(-1,1))\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

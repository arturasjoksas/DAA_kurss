{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lielo datu koncepti:  \n",
    "* MapReduce skaitļošanas paradigma\n",
    "* Batch processing\n",
    "* ETL vs ELT\n",
    "* Streaming\n",
    "* Lielo datu zoodārzs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kas ir MapReduce?  \n",
    "MapReduce ir datu apstrādes pieeja (arī modelis, paradigma), kura paļaujas uz vairākiem savstarpēji neatkarīgiem procesiem, lai risinātu kādu problēmu.  \n",
    "\n",
    "Lielo datu pasaulē, šie neatkarīgi procesi norisinās uz neatkarīgiem virtuāliem vai fiziskiem serveriem (cluster nodes) uz kuriem jau glabājas kāda daļa no visas datu kopas (vai arī tai var viegli piekļūt) ar kuru strādājot mēs sagaidītu rezultātu. MapReduce procesi tipiski sastāv no 3 soļiem:  \n",
    "* Map  - Uz datiem lokāli veic kādu operāciju un atcerās šīs operācijas rezultātu  \n",
    "* Shuffle  - Ja nepieciešams, Map operācijas rezultāti tiek pārvietoti starp klastera nodēm  \n",
    "* Reduce - Klastera nodes tad apstrādā Map operāciju rezultātus neatkarīgi viena no otras.  \n",
    "\n",
    "Ideālā gadījumā, ja mums ir k klastera nodes, laiks, kas ir nepieciešams, lai atrisinātu problēmu, kuras 'izmērs' ir N, mēs esam samazinājuši nepieciešamo darbību skaitu k reizes. Jāņem vērā, ka ideāls gadījums reti kad izpildās vairāku iemeslu dēļ.  \n",
    "\n",
    "**Shuffle** operācija bieži ir vislaikietilpīgākā daļa no visa mapreduce procesa tīkla/atmiņas bottleneck dēļ.  \n",
    "To ir iespējams optimizēt priekšlaicīgi izvietojot datus tā, lai shuffle būtu pēc iespējams minimāls t.i. Ierakstus, uz kuriem jāveic reduce operācija visiem kopā arī glabā kopā.  \n",
    "\n",
    "Reduce funkcijas ievads reti kad ir vienāda izmēra uz visām klastera nodēm.  \n",
    "Piem ja mums ir tabula, kurai veicam group by darbību un kolonnā pēc kuras grupējam mums vērtība 'A' parādās 10 reizes vairāk kā jebkura cita vērtība, tad viena klastera node mums arī aizņems daudz ilgāku laiku, iespējams pilnībā izdzēšot visu paralelizācijas ieguvumu. Šis ir tas, ko mēs saucam par **Skewed** jeb nošķiebtiem datiem. Viens programmistisks risinājums - salting + divi group by.  \n",
    "Šī ir arī problēma ar kuru saskarās arī statistikā, kad kāda apakškopa no populācijas ir pārmērīgi 'reprezentēta'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kas ir batch processing?  \n",
    "Batch processing ir datu apstrādes tehnika, kur liels ierakstu skaits tiek automatizēti pārveidots vai pārvietots vienā vai vairākos soļos. Batch processing tipiski darbojas ar statiskiem, nekustīgiem datiem.  \n",
    "Batch procesu piemēri ir sekojošie: \n",
    "* Galveno lientu - pakalpojumu - statusu tabulu atjaunināšana reizi dienā plkst 5:00 no rīta, \n",
    "* Saraksta, kur katra rūtera izdalītās IP adrese tiek salikta ar laiku, kad šīs adreses tika rezervētas un kad bija aktīvas, atsvaidzināšana,  \n",
    "* Vēsturisko datu tabulu papildināšana ar aktuālo informāciju.\n",
    "Batch process var būt jebkurš automatizējams datubāzes vaicājums. Galvenais - batch process tipiski atsaucās uz jebkuru darbību uz nekustīgiem datiem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kas ir ETL? Kas ir ELT? Ar ko tie atšķirās?  \n",
    "ETL ir saīsinājums no Extract Transform Load.  \n",
    "ELT ir saīsinājums no Extract Load Transform.\n",
    "\n",
    "Datu transformēšanas darbības gandrīz vienmēr ir sadalītas datu ielādē, datu transformācijā un datu ierakstīšanā. **ETL** ir datu ielāde no avota kādā rīkā/vidē, kur tad uz datiem tiek veiktas transformācijas. Šo transformāciju rezultāts tad tiek ielādēts datubāzes tabulās. Transformācija tiek veikta pirms ielādes.  \n",
    "\n",
    "**ELT** atšķirās tikai ar to, kur skaitļošanas darbība tiek veikta. Ja mēs ielādējam datus no kādas ārējās sistēmas (piem API) datu noliktavā, kur automatizēts skripts tad šos datus apstrādā un saliek, kur nepieciešams, tas ir ELT. Transformācija kā pēdējais solis. Dati tika ielādēti, pirms transformēti.  \n",
    "\n",
    "\n",
    "\n",
    "Tāpat kā mums reti kad ir tīras faktu/dimensiju tabulas, reālā produkcijas sistēmā tas, kur dati tiek transformēti ir atkarīgs no pieejamajiem resursiem.  \n",
    "\n",
    "Piem.:  Datubāze nav tik noslogota, lai tā reizi dienā nevarētu veikt kādas transformācijas uz svaigi ielādētiem datiem.  \n",
    "\n",
    "Piem. : Alternatīvi, mums uz datu nav daudz, bet aprēķini/joini/grupēšanas ir skaitliski intensīvas vai aizņem ilgu laiku uz datubāzes. Šādā gadījumā pieeja varētu būt īslaicīgi pacelt virtuālās mašīnas mākonī, ielādēt datus tur, veikt aprēķinus mākonī un rezultātu ielādēt atpakaļ datubāzē."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kas ir datu straumēšana?  \n",
    "Straumēti dati ir situācija, kad mums dati ir nevis statiski, bet gan nepārtraukti atjaunoti. Atkarībā no datu satura, varētu būt nepieciešams veikt dažādas darbības. Straumēti dati ir plašs jēdziens zem kura var palikt diezgan plašu klāstu ar darbībām. \n",
    "\n",
    "* Liela ātruma transakciju apstrāde bankā,\n",
    "* Reāla vai gandrīz reāla laika rekomendācijas, bāzējoties uz saturu, kas tiek skatīts \n",
    "* Kāda lietotāja transakcija vai darbība ātri jāsalīdzina ar lietotāja pagātnes darbībām un bāzējoties uz tā, jāatzīmē kā aizdomīga vai arī jābloķē. \n",
    "* Real time dashboardi vai anomāliju detektēšana.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ko tad lietot?  \n",
    "\n",
    "\n",
    "~90% gadījumu lielo datu tehnoloģija pat nav nepieciešama un doto problēmu var atrisināt savādāk ar labāku shēmu, labāku plānošanu, kādu populāru risinājumu vai dažiem funkcionalitāšu kompromisiem.  \n",
    "\n",
    "Bet, pat ja tiek lietota klasiskā RDBMS, shēmu un sistēmu plānošanu labāk atstāt pieredzējušiem izstrādātājiem. \n",
    "\n",
    "Lielo datu apstrādes/analīzes sistēmās ir ļoti daudzi aspekti, ko ņemt vērā, sākot no GDPR līdz tam, vai atsevišķas partīcijas nepārsniegs klastera nodes atļautās operatīvās atmiņas sliekšņus, potenciālās join operāciju optimizācijas, pieejas tiesības kādas būtu jādod analītiķiem, kas ar ielādētajiem datiem strādās u.t.t.\n",
    "\n",
    "**Pareizā pieeja ir nevis izvēlēties rīku un mēģināt to lietot, bet saprast risināmo problēmu un tad piekārtot pareizo rīku**  \n",
    "\n",
    "Tas, savukārt prasa zināšanas par rīkiem. Kurš dara ko, kurš strādās ātrāk un efektīvāk, kurš prasīs vairāk izstrādes laika. Lielo datu pasaulē projektu vadītājam ir jābūt labām lielo datu *landscape* zināšanām."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Šis ir lielo datu landscape 2019. gadā. Iekļauti atsevišķu programmatūru un pakalpojumu vendori, atsevišķas platformas un frameworki, kas rīkus apvieno, pa virsu uzliekot savu kodu, kā arī klasiskie spēlētāji kā Microsoft un Oracle ar saviem produktiem.  \n",
    "\n",
    "![Lielo datu landscape 2019](http://mattturck.com/wp-content/uploads/2019/07/2019_Matt_Turck_Big_Data_Landscape_Final_Fullsize.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
